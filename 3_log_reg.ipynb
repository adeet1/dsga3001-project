{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"adult.data\", delimiter=\", \", engine='python', names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                                                                         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0              2174             0              40  United-States  <=50K  \n",
       "1                 0             0              13  United-States  <=50K  \n",
       "2                 0             0              40  United-States  <=50K  \n",
       "3                 0             0              40  United-States  <=50K  \n",
       "4                 0             0              40           Cuba  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32556             0             0              38  United-States  <=50K  \n",
       "32557             0             0              40  United-States   >50K  \n",
       "32558             0             0              40  United-States  <=50K  \n",
       "32559             0             0              20  United-States  <=50K  \n",
       "32560         15024             0              40  United-States   >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[[\"age\", \"fnlwgt\", \"education-num\", \"income\"]].copy()\n",
    "temp[\"income\"] = (temp.income==\">50K\").astype('int')\n",
    "y = temp[[\"income\"]].values\n",
    "X = temp[[\"age\", \"fnlwgt\", \"education-num\"]].copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, bs, epochs, lr):\n",
    "    m2, n2 = X.shape\n",
    "    \n",
    "    # Initializing weights and bias to zeros.\n",
    "    w = np.zeros((n2,1))\n",
    "    b = 0\n",
    "    \n",
    "    # Reshape y.\n",
    "    y = y.reshape(m2,1)\n",
    "    \n",
    "    # Normalize inputs\n",
    "    #x = normalize(X)\n",
    "    #____________________change 1\n",
    "    m, n = X.shape\n",
    "    for i in range(n):\n",
    "        X = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "    #______________________________\n",
    "    \n",
    "    \n",
    "    # Store losses\n",
    "    losses = []\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((m2-1)//bs + 1):\n",
    "            \n",
    "            # Defining batches for SGD (this can be changed)\n",
    "            start_i = i*bs\n",
    "            end_i = start_i + bs\n",
    "            xb = X[start_i:end_i]\n",
    "            yb = y[start_i:end_i]\n",
    "            \n",
    "            # Predict\n",
    "            #y_hat = sigmoid(np.dot(xb, w) + b)\n",
    "            #____________________change 4\n",
    "            y_hat =1.0/(1 + np.exp(-(np.dot(xb, w) + b)))\n",
    "            #_____________________\n",
    "            \n",
    "            \n",
    "            # Calculate gradients\n",
    "            #dw, db = gradients(xb, yb, y_hat)\n",
    "            #____________________________change 2\n",
    "            m1 = xb.shape[0]\n",
    "            # Gradient of loss w.r.t weights\n",
    "            #dw = (1/m1)*np.dot(xb.T,(y_hat - yb))\n",
    "            # Gradient of loss w.r.t bias\n",
    "            #db = (1/m1)*np.sum((y_hat - yb)) \n",
    "            #______________________________\n",
    "            # Update params\n",
    "            w -= lr*(1/m1)*np.dot(xb.T,(y_hat - yb))\n",
    "            b -= lr*(1/m1)*np.sum((y_hat - yb)) \n",
    "        \n",
    "        # Calc loss\n",
    "        #l = loss(x, y, w)\n",
    "        #_________________________change 3\n",
    "        margin = np.dot(X, w)\n",
    "        losses.append(y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin)))))\n",
    "        #_________________________\n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    \n",
    "    # X --> Input.\n",
    "    \n",
    "    # Normalizing the inputs.\n",
    "    #x = normalize(X)\n",
    "    #_____________________change 6\n",
    "    m, n = X.shape\n",
    "    for i in range(n):\n",
    "        X = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "    #_______________________\n",
    "    \n",
    "    # Calculating presictions/y_hat.\n",
    "    #preds = sigmoid(np.dot(X, w) + b)\n",
    "    #______________________change 5\n",
    "    preds = 1.0/(1 + np.exp(-(np.dot(X, w) + b)))\n",
    "    #_______________________\n",
    "    \n",
    "    # if y_hat >= 0.5 --> round up to 1\n",
    "    # if y_hat < 0.5 --> round up to 1\n",
    "    pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
    "    \n",
    "    return np.array(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    accuracy = np.sum(y == y_hat) / len(y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f train w, b, l = train(X, y, bs=100, epochs=1000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training \n",
    "for i in range(10):\n",
    "    w, b, l = train(X, y, bs=100, epochs=1000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[0.59660644]\n",
      " [0.04652271]\n",
      " [0.93286765]], beta: -1.4200837383939489\n"
     ]
    }
   ],
   "source": [
    "print(f'weights: {w}, beta: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'logistic_regression'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-235ddade2335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlogistic_regression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'logistic_regression'"
     ]
    }
   ],
   "source": [
    "from logistic_regression import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_epochs=1000, learning_rate=0.001, batch_size=100)\n",
    "lr.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'weights: {lr.get_weights()}, beta: {lr.get_bias()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "\n",
    "### Step 1: Clean (and slow) baseline\n",
    "\n",
    "- Change code into singular class? (for presentability)\n",
    "\n",
    "- Implement minibatch if it isn't already\n",
    "\n",
    "- Add in regularization\n",
    "\n",
    "- Replace np.sum(), np.dot(), np.mean(), etc. with handmade functions\n",
    "\n",
    "- Implement data science pipeline (including grid search)\n",
    "\n",
    "\n",
    "### Step 2: Speed up\n",
    "\n",
    "Find different methods to improve baseline and implement (look through syllabus):\n",
    "\n",
    "1) Use numpy\n",
    "\n",
    "2) Cython\n",
    "\n",
    "3) Parallel computing (esp. for gradient descent)\n",
    "\n",
    "4) ...\n",
    "\n",
    "\n",
    "#### Minor step 3: Get clean output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timer unit: 1e-07 s\n",
    "\n",
    "Total time: 34.0118 s\n",
    "File: <ipython-input-9-7301afd39c54>\n",
    "Function: train at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def train(X, y, bs, epochs, lr):\n",
    "     2         1         64.0     64.0      0.0      m2, n2 = X.shape\n",
    "     3                                               \n",
    "     4                                               # Initializing weights and bias to zeros.\n",
    "     5         1        120.0    120.0      0.0      w = np.zeros((n2,1))\n",
    "     6         1         11.0     11.0      0.0      b = 0\n",
    "     7                                               \n",
    "     8                                               # Reshape y.\n",
    "     9         1         96.0     96.0      0.0      y = y.reshape(m2,1)\n",
    "    10                                               \n",
    "    11                                               # Normalize inputs\n",
    "    12                                               #x = normalize(X)\n",
    "    13                                               #____________________change 1\n",
    "    14         1         13.0     13.0      0.0      m, n = X.shape\n",
    "    15         4        779.0    194.8      0.0      for i in range(n):\n",
    "    16         3      66893.0  22297.7      0.0          X = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "    17                                               #______________________________\n",
    "    18                                               \n",
    "    19                                               \n",
    "    20                                               # Store losses\n",
    "    21         1         12.0     12.0      0.0      losses = []\n",
    "    22                                               \n",
    "    23                                               # Train\n",
    "    24      1001      29475.0     29.4      0.0      for epoch in range(epochs):\n",
    "    25    327000    4837793.0     14.8      1.4          for i in range((m2-1)//bs + 1):\n",
    "    26                                                       \n",
    "    27                                                       # Defining batches for SGD (this can be changed)\n",
    "    28    326000    4746645.0     14.6      1.4              start_i = i*bs\n",
    "    29    326000    4810686.0     14.8      1.4              end_i = start_i + bs\n",
    "    30    326000    7123366.0     21.9      2.1              xb = X[start_i:end_i]\n",
    "    31    326000    6585917.0     20.2      1.9              yb = y[start_i:end_i]\n",
    "    32                                                       \n",
    "    33                                                       # Predict\n",
    "    34                                                       #y_hat = sigmoid(np.dot(xb, w) + b)\n",
    "    35                                                       #____________________change 4\n",
    "    36    326000   84449182.0    259.0     24.8              y_hat =1.0/(1 + np.exp(-(np.dot(xb, w) + b)))\n",
    "    37                                                       #_____________________\n",
    "    38                                                       \n",
    "    39                                                       \n",
    "    40                                                       # Calculate gradients\n",
    "    41                                                       #dw, db = gradients(xb, yb, y_hat)\n",
    "    42                                                       #____________________________change 2\n",
    "    43    326000    6527809.0     20.0      1.9              m1 = xb.shape[0]\n",
    "    44                                                       # Gradient of loss w.r.t weights\n",
    "    45                                                       #dw = (1/m1)*np.dot(xb.T,(y_hat - yb))\n",
    "    46                                                       # Gradient of loss w.r.t bias\n",
    "    47                                                       #db = (1/m1)*np.sum((y_hat - yb)) \n",
    "    48                                                       #______________________________\n",
    "    49                                                       # Update params\n",
    "    50    326000   67845472.0    208.1     19.9              w -= lr*(1/m1)*np.dot(xb.T,(y_hat - yb))\n",
    "    51    326000   91315407.0    280.1     26.8              b -= lr*(1/m1)*np.sum((y_hat - yb)) \n",
    "    52                                                   \n",
    "    53                                                   # Calc loss\n",
    "    54                                                   #l = loss(x, y, w)\n",
    "    55                                                   #_________________________change 3\n",
    "    56      1000     873189.0    873.2      0.3          margin = np.dot(X, w)\n",
    "    57      1000   60904927.0  60904.9     17.9          losses.append(y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin)))))\n",
    "    58                                                   #_________________________\n",
    "    59         1         18.0     18.0      0.0      return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
