{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"adult.data\", delimiter=\", \", engine='python', names=['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                                                                         'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32560</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32561 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt   education  education-num  \\\n",
       "0       39         State-gov   77516   Bachelors             13   \n",
       "1       50  Self-emp-not-inc   83311   Bachelors             13   \n",
       "2       38           Private  215646     HS-grad              9   \n",
       "3       53           Private  234721        11th              7   \n",
       "4       28           Private  338409   Bachelors             13   \n",
       "...    ...               ...     ...         ...            ...   \n",
       "32556   27           Private  257302  Assoc-acdm             12   \n",
       "32557   40           Private  154374     HS-grad              9   \n",
       "32558   58           Private  151910     HS-grad              9   \n",
       "32559   22           Private  201490     HS-grad              9   \n",
       "32560   52      Self-emp-inc  287927     HS-grad              9   \n",
       "\n",
       "           marital-status         occupation   relationship   race     sex  \\\n",
       "0           Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1      Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2                Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3      Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4      Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "...                   ...                ...            ...    ...     ...   \n",
       "32556  Married-civ-spouse       Tech-support           Wife  White  Female   \n",
       "32557  Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
       "32558             Widowed       Adm-clerical      Unmarried  White  Female   \n",
       "32559       Never-married       Adm-clerical      Own-child  White    Male   \n",
       "32560  Married-civ-spouse    Exec-managerial           Wife  White  Female   \n",
       "\n",
       "       capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0              2174             0              40  United-States  <=50K  \n",
       "1                 0             0              13  United-States  <=50K  \n",
       "2                 0             0              40  United-States  <=50K  \n",
       "3                 0             0              40  United-States  <=50K  \n",
       "4                 0             0              40           Cuba  <=50K  \n",
       "...             ...           ...             ...            ...    ...  \n",
       "32556             0             0              38  United-States  <=50K  \n",
       "32557             0             0              40  United-States   >50K  \n",
       "32558             0             0              40  United-States  <=50K  \n",
       "32559             0             0              20  United-States  <=50K  \n",
       "32560         15024             0              40  United-States   >50K  \n",
       "\n",
       "[32561 rows x 15 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[[\"age\", \"fnlwgt\", \"education-num\", \"income\"]].copy()\n",
    "temp[\"income\"] = (temp.income==\">50K\").astype('int')\n",
    "y = temp[[\"income\"]].values\n",
    "X = temp[[\"age\", \"fnlwgt\", \"education-num\"]].copy().to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1.0/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, y, w):\n",
    "    margin = np.dot(X, w)\n",
    "    \n",
    "    return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(X, y, y_hat):\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # Gradient of loss w.r.t weights\n",
    "    dw = (1/m)*np.dot(X.T, (y_hat - y))\n",
    "    \n",
    "    # Gradient of loss w.r.t bias\n",
    "    db = (1/m)*np.sum((y_hat - y)) \n",
    "    \n",
    "    return dw, db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(X): \n",
    "    m, n = X.shape\n",
    "\n",
    "    for i in range(n):\n",
    "        X = (X - X.mean(axis=0))/X.std(axis=0)\n",
    "        \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y, bs, epochs, lr):\n",
    "    m, n = X.shape\n",
    "    \n",
    "    # Initializing weights and bias to zeros.\n",
    "    w = np.zeros((n,1))\n",
    "    b = 0\n",
    "    \n",
    "    # Reshape y.\n",
    "    y = y.reshape(m,1)\n",
    "    \n",
    "    # Normalize inputs\n",
    "    x = normalize(X)\n",
    "    \n",
    "    # Store losses\n",
    "    losses = []\n",
    "    \n",
    "    # Train\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((m-1)//bs + 1):\n",
    "            \n",
    "            # Defining batches for SGD (this can be changed)\n",
    "            start_i = i*bs\n",
    "            end_i = start_i + bs\n",
    "            xb = X[start_i:end_i]\n",
    "            yb = y[start_i:end_i]\n",
    "            \n",
    "            # Predict\n",
    "            y_hat = sigmoid(np.dot(xb, w) + b)\n",
    "            \n",
    "            # Calculate gradients\n",
    "            dw, db = gradients(xb, yb, y_hat)\n",
    "            \n",
    "            # Update params\n",
    "            w -= lr*dw\n",
    "            b -= lr*db\n",
    "        \n",
    "        # Calc loss\n",
    "        l = loss(x, y, w)\n",
    "        losses.append(l)\n",
    "        \n",
    "    return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X):\n",
    "    \n",
    "    # X --> Input.\n",
    "    \n",
    "    # Normalizing the inputs.\n",
    "    x = normalize(X)\n",
    "    \n",
    "    # Calculating presictions/y_hat.\n",
    "    preds = sigmoid(np.dot(X, w) + b)\n",
    "    \n",
    "    # if y_hat >= 0.5 --> round up to 1\n",
    "    # if y_hat < 0.5 --> round up to 1\n",
    "    pred_class = [1 if i > 0.5 else 0 for i in preds]\n",
    "    \n",
    "    return np.array(pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    accuracy = np.sum(y == y_hat) / len(y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-2837dfe2f958>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1 + np.exp(-z))\n",
      "<ipython-input-6-446f1ee1a133>:4: RuntimeWarning: overflow encountered in exp\n",
      "  return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))\n",
      "<ipython-input-6-446f1ee1a133>:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))\n",
      "<ipython-input-6-446f1ee1a133>:4: RuntimeWarning: invalid value encountered in logaddexp\n",
      "  return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))\n",
      "<ipython-input-6-446f1ee1a133>:4: RuntimeWarning: overflow encountered in add\n",
      "  return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))\n"
     ]
    }
   ],
   "source": [
    "%lprun -f train w, b, l = train(X, y, bs=100, epochs=1000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-2837dfe2f958>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0/(1 + np.exp(-z))\n",
      "<ipython-input-6-446f1ee1a133>:4: RuntimeWarning: overflow encountered in exp\n",
      "  return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))\n",
      "<ipython-input-6-446f1ee1a133>:4: RuntimeWarning: invalid value encountered in multiply\n",
      "  return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))\n",
      "<ipython-input-6-446f1ee1a133>:4: RuntimeWarning: invalid value encountered in logaddexp\n",
      "  return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))\n",
      "<ipython-input-6-446f1ee1a133>:4: RuntimeWarning: overflow encountered in add\n",
      "  return y * -np.logaddexp(0, np.exp(margin) + (1 - y) * (1 + np.logaddexp(0, np.exp(margin))))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Training \n",
    "for i in range(10):\n",
    "    w, b, l = train(X, y, bs=100, epochs=1000, lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weights: [[476.68326575]\n",
      " [-49.8336871 ]\n",
      " [126.64328737]], beta: 0.49218514721669687\n"
     ]
    }
   ],
   "source": [
    "print(f'weights: {w}, beta: {b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'logistic_regression'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-235ddade2335>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlogistic_regression\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'logistic_regression'"
     ]
    }
   ],
   "source": [
    "from logistic_regression import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_epochs=1000, learning_rate=0.001, batch_size=100)\n",
    "lr.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'weights: {lr.get_weights()}, beta: {lr.get_bias()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TO DO:\n",
    "\n",
    "### Step 1: Clean (and slow) baseline\n",
    "\n",
    "- Change code into singular class? (for presentability)\n",
    "\n",
    "- Implement minibatch if it isn't already\n",
    "\n",
    "- Add in regularization\n",
    "\n",
    "- Replace np.sum(), np.dot(), np.mean(), etc. with handmade functions\n",
    "\n",
    "- Implement data science pipeline (including grid search)\n",
    "\n",
    "\n",
    "### Step 2: Speed up\n",
    "\n",
    "Find different methods to improve baseline and implement (look through syllabus):\n",
    "\n",
    "1) Use numpy\n",
    "\n",
    "2) Cython\n",
    "\n",
    "3) Parallel computing (esp. for gradient descent)\n",
    "\n",
    "4) ...\n",
    "\n",
    "\n",
    "#### Minor step 3: Get clean output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Timer unit: 1e-07 s\n",
    "\n",
    "Total time: 43.397 s\n",
    "File: <ipython-input-9-a765c3261458>\n",
    "Function: train at line 1\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     1                                           def train(X, y, bs, epochs, lr):\n",
    "     2         1        105.0    105.0      0.0      m, n = X.shape\n",
    "     3                                               \n",
    "     4                                               # Initializing weights and bias to zeros.\n",
    "     5         1        294.0    294.0      0.0      w = np.zeros((n,1))\n",
    "     6         1         11.0     11.0      0.0      b = 0\n",
    "     7                                               \n",
    "     8                                               # Reshape y.\n",
    "     9         1        113.0    113.0      0.0      y = y.reshape(m,1)\n",
    "    10                                               \n",
    "    11                                               # Normalize inputs\n",
    "    12         1      83837.0  83837.0      0.0      x = normalize(X)\n",
    "    13                                               \n",
    "    14                                               # Store losses\n",
    "    15         1         33.0     33.0      0.0      losses = []\n",
    "    16                                               \n",
    "    17                                               # Train\n",
    "    18      1001      13813.0     13.8      0.0      for epoch in range(epochs):\n",
    "    19    327000    3537322.0     10.8      0.8          for i in range((m-1)//bs + 1):\n",
    "    20                                                       \n",
    "    21                                                       # Defining batches for SGD (this can be changed)\n",
    "    22    326000    4032589.0     12.4      0.9              start_i = i*bs\n",
    "    23    326000    4141838.0     12.7      1.0              end_i = start_i + bs\n",
    "    24    326000    6599091.0     20.2      1.5              xb = X[start_i:end_i]\n",
    "    25    326000    5866080.0     18.0      1.4              yb = y[start_i:end_i]\n",
    "    26                                                       \n",
    "    27                                                       # Predict\n",
    "    28    326000  139321947.0    427.4     32.1              y_hat = sigmoid(np.dot(xb, w) + b)\n",
    "    29                                                       \n",
    "    30                                                       # Calculate gradients\n",
    "    31    326000  156206727.0    479.2     36.0              dw, db = gradients(xb, yb, y_hat)\n",
    "    32                                                       \n",
    "    33                                                       # Update params\n",
    "    34    326000   24956511.0     76.6      5.8              w -= lr*dw\n",
    "    35    326000    6578424.0     20.2      1.5              b -= lr*db\n",
    "    36                                                   \n",
    "    37                                                   # Calc loss\n",
    "    38      1000   82587821.0  82587.8     19.0          l = loss(x, y, w)\n",
    "    39      1000      43858.0     43.9      0.0          losses.append(l)\n",
    "    40                                                   \n",
    "    41         1         14.0     14.0      0.0      return w, b, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
